{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import PIL.Image\n",
    "import urllib.request\n",
    "from tensorflow.python.platform import gfile \n",
    "import zipfile  \n",
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip\n"
     ]
    }
   ],
   "source": [
    "#why do this, maybe for the artistic purpose or produce some artifacts for fun \n",
    "# work_dir=os.mkdir('deepdream') \n",
    "work_dir=''\n",
    "model_url= 'https://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip' \n",
    "print(model_url) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name= model_url.split('/')[-1] \n",
    "file_path= os.path.join(work_dir, file_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(file_path):\n",
    "    file_path, _= urllib.request.urlretrieve(model_url, file_path)  \n",
    "zip_handle= zipfile.ZipFile(file_path, 'r') \n",
    "zip_handle.extractall(work_dir) \n",
    "zip_handle.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tensorflow_inception_graph.pb'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pretrain model can be load into session \n",
    "graph= tf.Graph() \n",
    "session= tf.InteractiveSession(graph=graph)\n",
    "model_path= os.path.join(work_dir, 'tensorflow_inception_graph.pb') \n",
    "model_path  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0731 15:43:09.859522 4594554304 deprecation.py:323] From <ipython-input-6-7943cfdc016a>:1: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n"
     ]
    }
   ],
   "source": [
    "with gfile.FastGFile(model_path,'rb') as f:\n",
    "    graph_defnition= tf.GraphDef() \n",
    "    graph_defnition.ParseFromString(f.read()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_placeholder= tf.placeholder(np.float32, name='input') \n",
    "#set the name so that can be check this on the graph in the tensorboard \n",
    "imagenet_mean_value= 117.0\n",
    "preprocessed_input= tf.expand_dims(input_placeholder - imagenet_mean_value,0)\n",
    "tf.import_graph_def(graph_defnition, {'input':preprocessed_input})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now the session and graph is ready for the inference \n",
    "def resize_image(image, size):\n",
    "    resize_placeholder= tf.placeholder(tf.float32) \n",
    "    resize_placeholder_expand= tf.expand_dims(resize_placeholder,0) \n",
    "    resized_image= tf.image.resize_bilinear(resize_placeholder_expand, size)[0,:,:,:]\n",
    "    return session.run(resized_image, feed_dict={resize_placeholder:image})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name= 'nat_chloe.JPG' \n",
    "image= PIL.Image.open(image_name)\n",
    "image=np.float32(image) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the number of octave, scale and window_size \n",
    "objective_fn = tf.square(graph.get_tensor_by_name(\"import/mixed4c:0\")) \n",
    "\n",
    "no_octave= 4 \n",
    "scale= 1.4\n",
    "window_size= 51\n",
    "score= tf.reduce_mean(objective_fn)  \n",
    "gradients= tf.gradients(score, input_placeholder)[0]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "octave_images=[]\n",
    "\n",
    "for i in range(no_octave-1):\n",
    "    image_height_width= image.shape[:2] \n",
    "    scaled_image= resize_image(image, np.int32(np.float32(image_height_width)/scale)) \n",
    "    image_difference= image- resize_image(scaled_image, image_height_width)\n",
    "    image= scaled_image\n",
    "    octave_images.append(image_difference)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "#let's create the dream \n",
    "for octave_idx in range(no_octave):\n",
    "    if octave_idx>0:\n",
    "        image_difference= octave_images[-octave_idx] \n",
    "        image= resize_image(image, image_difference.shape[:2]) + image_difference\n",
    "        \n",
    "    for i in range(10):\n",
    "        image_height, image_width= image.shape[:2] \n",
    "        sx,sy= np.random.randint(window_size, size=2) \n",
    "        shifted_image= np.roll(np.roll(image, sx,1), sy,0) \n",
    "        gradient_values= np.zeros_like(image) \n",
    "            \n",
    "        for y in range(0, max(image_height - window_size//2, window_size),window_size):\n",
    "            for x in range(0, max(image_width - window_size//2, window_size), window_size):\n",
    "                sub= shifted_image[y:y+window_size,x:x+window_size] \n",
    "                gradient_windows= session.run(gradients, {input_placeholder:sub}) \n",
    "                gradient_values[y:y+window_size, x:x+window_size] = gradient_windows  \n",
    "                gradient_windows= np.roll(np.roll(gradient_values, -sx, 1),-sy,0) \n",
    "                image+= gradient_windows *(1.5/(np.abs(gradient_windows).mean()+ 1e-7))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the deep dream image \n",
    "image /= 255.0 \n",
    "image = np.uint8(np.clip(image,0,1)*255) \n",
    "PIL.Image.fromarray(image).save('deep_'+image_name,'jpeg') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
